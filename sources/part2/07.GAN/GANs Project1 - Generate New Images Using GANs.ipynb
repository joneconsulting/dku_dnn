{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1601697138771,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "W7G5RvJ9Ilw8"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "elapsed": 3455,
     "status": "ok",
     "timestamp": 1601697141242,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "t3QythVEJKEC",
    "outputId": "59dcf499-9980-4a5a-aedc-972376913a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /opt/anaconda3/lib/python3.8/site-packages (2.9.0)\r\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.8/site-packages (from imageio) (7.2.0)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from imageio) (1.18.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4791,
     "status": "ok",
     "timestamp": 1601697142584,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "hJ7RflLuJS-u"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwMQH4aTJWlD"
   },
   "source": [
    "### STEP #1: IMPORT DATASETS AND NORMALIZE IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 1341,
     "status": "ok",
     "timestamp": 1601698128006,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "vtTdJ4iTJUlp",
    "outputId": "2149a2fb-d7ad-44e4-8d9b-94e882aec75c"
   },
   "outputs": [],
   "source": [
    "# (train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 4779,
     "status": "ok",
     "timestamp": 1601697142586,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "P6Q3cNpPJZa8",
    "outputId": "35a0fdd4-8dbe-4230-fd17-a3a5a82f3207"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 4772,
     "status": "ok",
     "timestamp": 1601697142586,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "x7VeFZ6WJbFA",
    "outputId": "92c97eb9-ff90-4a5d-9b47-7609388f4ff3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 981,
     "status": "ok",
     "timestamp": 1601698131499,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "yPNgRDOZJb7r"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 961,
     "status": "ok",
     "timestamp": 1601698132958,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "09jjc-9KJc10",
    "outputId": "ccd2f4c2-01b2-4406-8072-c7c984ec0091"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1120,
     "status": "ok",
     "timestamp": 1601698133914,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "2bnsliLnJd8V"
   },
   "outputs": [],
   "source": [
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1034,
     "status": "ok",
     "timestamp": 1601698135072,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "ane_7OJ0JfOs"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 653,
     "status": "ok",
     "timestamp": 1601698135422,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "oUJ59VhUJgkC"
   },
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDrZtgkgJiya"
   },
   "source": [
    "### STEP #2: VISUALIZE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1601698159849,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "J6oGYGOuJk8J",
    "outputId": "dda50483-3a1f-4432-dc49-ba892e37e87b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9099696850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[110].reshape((28,28)) , cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6raz784eJpmC"
   },
   "source": [
    "### STEP #3: BUILD GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6040,
     "status": "ok",
     "timestamp": 1601697143891,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "sej4BjnsJsVa"
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,))) # 12544\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "\n",
    "    # Because we used \"same\" padding and stride = 1, the output is the same size as input 7 x 7 but with 128 filters instead\n",
    "    # Resulting in 7 x 7 x 128\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)) \n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Because we used \"same\" padding and stride = 2, the output is double the size of the input 14 x 14 but with 64 filters instead\n",
    "    # Resulting in 14 x 14 x 64\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Because we used \"same\" padding and stride = 2, the output is double the size of the input 28 x 28 but with 1 filter instead\n",
    "    # Resulting in 28 x 28 x 1\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "executionInfo": {
     "elapsed": 6035,
     "status": "ok",
     "timestamp": 1601697143892,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "xVHx3m2nKYGn",
    "outputId": "e00bfdf4-1bbd-4a63-cb67-3e43eeb36ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600      \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's test it and check the dimensions\n",
    "generator = make_generator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1151,
     "status": "ok",
     "timestamp": 1601698186257,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "cC9SXMqyKZr7",
    "outputId": "ab077ad7-39ca-4169-e321-956fa3df3289"
   },
   "outputs": [],
   "source": [
    "# Let's test it with a random noise seed and see the output\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 995,
     "status": "ok",
     "timestamp": 1601698188713,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "7gQkUJD1Kau5",
    "outputId": "4095edd6-d8de-4c93-f001-c5d23b480ef5"
   },
   "outputs": [],
   "source": [
    "plt.imshow(generated_image[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKV3tPCOKj_P"
   },
   "source": [
    "### STEP#4: BUILD THE DISCRIMINATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7633,
     "status": "ok",
     "timestamp": 1601697145515,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "CMfXzvpwKccv"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "executionInfo": {
     "elapsed": 959,
     "status": "ok",
     "timestamp": 1601698194126,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "Im_pbJXeMLyz",
    "outputId": "d12414a7-266c-4666-9d9d-072c3c5fe8ec"
   },
   "outputs": [],
   "source": [
    "# Let's see the model structure\n",
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1018,
     "status": "ok",
     "timestamp": 1601698198599,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "se8f1KMoMNa7",
    "outputId": "b04120e6-aedb-4ff7-8ffa-67ddc08bbfe8"
   },
   "outputs": [],
   "source": [
    "# Give it a shot and see if the discriminator was able to classify the image or not! \n",
    "# The model will be trained to output positive values for real images, and negative values for fake images.\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVIAqXjaMO5D"
   },
   "source": [
    "### STEP #5: DEFINE THE LOSS FUNCTIONS FOR BOTH NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1601698203515,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "-_iB9WBVk6VF"
   },
   "outputs": [],
   "source": [
    "# This computes the 'loss' which simply the difference between the model predictions and the true label\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7934,
     "status": "ok",
     "timestamp": 1601697145838,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "hBeiwe1-k_6E"
   },
   "outputs": [],
   "source": [
    "# The discriminator loss indicates how well the discriminator is able to distinguish real and fake images. \n",
    "# It compares the discriminator's predictions on real images to an array of 1s, \n",
    "# and the discriminator's predictions on fake (generated) images to an array of 0s.\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss # sum up both losses\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7930,
     "status": "ok",
     "timestamp": 1601697145839,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "1XrpaHFklRDe"
   },
   "outputs": [],
   "source": [
    "# The generator's loss quantifies how well it was able to trick the discriminator. \n",
    "# if the generator is performing well, the discriminator will classify the fake images as real (or 1). \n",
    "# Here, we will compare the discriminators decisions on the generated images to an array of 1s.\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 950,
     "status": "ok",
     "timestamp": 1601698208720,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "2ZViNjCPlU02"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 942,
     "status": "ok",
     "timestamp": 1601698212388,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "1t5CM-oUlYHZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XHDhvwpk26z"
   },
   "source": [
    "### STEP#6: TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1601698215922,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "fy5CCVgwMRyb"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1601698222204,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "Ok9MqNewNC7T"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True) # step 1. call the generator and feed in the noise seed\n",
    "\n",
    "      real_output = discriminator(images, training=True) # step 2. pass the fake and real ones to discriminator to perform classification\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output) # step 3. Calculate the loss for both the generator and discriminator\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables) # step 4. calculate the gradient of the losses\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) # step 5. Apply the optimizers and update weights\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1601698223488,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "U4U3RwiLNG4R"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1601698226968,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "kbqg-Qh4ld2d"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ri1TKs3IpSJ_"
   },
   "source": [
    "#### EXECUTE FASHION_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 631138,
     "status": "ok",
     "timestamp": 1601698861144,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "KWA8h_5Olg-l",
    "outputId": "890fa00b-efbb-43f0-f7a2-7cb3ee3d5bfb"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1601698879516,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "KxMPvg-qnHEu",
    "outputId": "706af4de-de20-47ae-8a6e-455cc9480c45"
   },
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "executionInfo": {
     "elapsed": 835,
     "status": "ok",
     "timestamp": 1601698881025,
     "user": {
      "displayName": "Dowon Lee",
      "photoUrl": "",
      "userId": "13897648702981529913"
     },
     "user_tz": -540
    },
    "id": "URHQw1THlia2",
    "outputId": "77f772c5-88fd-412a-d58b-67dee90dc41e"
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
    "\n",
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBj--NMWpOl6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPH4rJZE1GUwB77LWKe2fe8",
   "collapsed_sections": [],
   "name": "GANs Project1 - Generate New Images Using GANs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
